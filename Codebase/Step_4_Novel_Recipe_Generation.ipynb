{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Mounting Google Drive for importing the Data Files which will be used in the Tokenization**"
      ],
      "metadata": {
        "id": "kTts_zswOGQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IGpbSsbJOUu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrDC5mrPMPs9"
      },
      "source": [
        "**Downloading, Installing & Importing Required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import trange\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from transformers import  AutoTokenizer,AutoModelWithLMHead"
      ],
      "metadata": {
        "id": "B0ulhDaBiuND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "OJKWq1EXiwH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Recipe Ingredient Tables**"
      ],
      "metadata": {
        "id": "DK9oArdli0qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table = pd.read_csv(\"Recipe_correct_ndb_updated_v1.csv\")"
      ],
      "metadata": {
        "id": "8NCXNw_piyFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fetching the \"recipe_no\" and \"ingredient\" columns**"
      ],
      "metadata": {
        "id": "JhvwrbFIi65R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recipe_ingredient_table = table[['recipe_no', 'ingredient']].copy()"
      ],
      "metadata": {
        "id": "44NoK_pvi8TM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation: Same ingredient is used more than once in the same recipe, for example \"water\" is used more than once in the recipe \"2610.0\"**"
      ],
      "metadata": {
        "id": "sYueXMRQi_pV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing Duplicate rows**"
      ],
      "metadata": {
        "id": "fQez_Lv3jC1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recipe_ingredient_table_unique = recipe_ingredient_table.drop_duplicates(keep = 'first')\n",
        "recipe_ingredient_table_unique = recipe_ingredient_table_unique[~recipe_ingredient_table_unique['ingredient'].isna()]"
      ],
      "metadata": {
        "id": "Axb8BVHEjFEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Table that maps Recipe number to its ingredients result is a Dictionary that maps Recipe number to its ingredients list**"
      ],
      "metadata": {
        "id": "vicqPhWyjMjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result=recipe_ingredient_table_unique.groupby('recipe_no')['ingredient'].apply(list).to_dict()\n",
        "keys = list(result.keys())\n",
        "values = list(result.values())\n",
        "recipe_size =[ len(listElem) for listElem in values]"
      ],
      "metadata": {
        "id": "aB8xPmFojRt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**final_df1 contains recipe_no, ingredients and recipe_size**"
      ],
      "metadata": {
        "id": "Ax-eDZRcjdHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame(list(zip(keys,values,recipe_size)),columns=['recipe_no','ingredients','recipe_size'])\n",
        "final_df1 = df1.sort_values(by=['recipe_size'])\n",
        "recipe_size_1 = final_df1.loc[final_df1['recipe_size'] == 1]\n",
        "recipe_id_size_one_list = recipe_size_1['recipe_no'].tolist()\n",
        "recipe_size_1_cooking_procedure = table[table['recipe_no'].isin(recipe_id_size_one_list)]"
      ],
      "metadata": {
        "id": "AH67SfIyjiMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing recipes from the \"recipe_ingredient_table_unique table\" with size equal to 1**"
      ],
      "metadata": {
        "id": "ShGR_coZjjGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recipe_ingredient_table_unique = recipe_ingredient_table_unique[~recipe_ingredient_table_unique['recipe_no'].isin(recipe_id_size_one_list)]"
      ],
      "metadata": {
        "id": "0pclkogsjnlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding count of each ingredient across the recipes**"
      ],
      "metadata": {
        "id": "_whd8h4bjqUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_count = recipe_ingredient_table_unique['ingredient'].value_counts()\n",
        "recipe_ingredient_table_count = pd.DataFrame({'ingredient': df_count.index, 'Recipe_Count':df_count.values})"
      ],
      "metadata": {
        "id": "wkjEOaO0jpqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluating the PMF(Probability Mass Function) and CDF(Cumulative Distribution Function) values for each ingredient**"
      ],
      "metadata": {
        "id": "Dsqdlzymjvhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ingredients_count = recipe_ingredient_table_count.shape[0]                             ## ingredients_count is the total number of unique ingredients across all the recipes\n",
        "recipe_count_list = recipe_ingredient_table_count['Recipe_Count'].tolist()             ## recipe_count_list contains the list of recipe_count for each ingredient \n",
        "recipe_count_list_unique = recipe_ingredient_table_count['Recipe_Count'].unique()      ## recipe_count_list_unique contains the unique values of recipe_counts\n",
        "\n",
        "pmf_list_unique = []                                                                   ## pmf_list_unique contains the pmf values corresponding to each recipe count\n",
        "for item in recipe_count_list_unique:\n",
        "    a = recipe_count_list.count(item)\n",
        "    # print(a)\n",
        "    pmf = a / ingredients_count\n",
        "    pmf_list_unique.append(pmf)\n",
        "\n",
        "cdf = 0                                                                                ## cdf_list_unique contains the cdf values corresponding to each recipe count\n",
        "cdf_list_unique = []\n",
        "for pmf in pmf_list_unique:\n",
        "    cdf = cdf + pmf\n",
        "    cdf_list_unique.append(cdf)\n",
        "\n",
        "data = {'Recipe_Count': recipe_count_list_unique ,'Pmf': pmf_list_unique, 'Cdf': cdf_list_unique}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df1 = pd.merge(recipe_ingredient_table_count, df, how='inner', on = 'Recipe_Count')"
      ],
      "metadata": {
        "id": "nCqodAnwjziG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Input Function that will perform the following tasks:**"
      ],
      "metadata": {
        "id": "UJWEuVxoj9Y7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Taking random n(number of ingredients to select) and fetching same number of ingredients based on random cdf values selected.**"
      ],
      "metadata": {
        "id": "Gk_pqWCekIOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. In case the randomly selected cdf value belongs to more than one ingredients, then we select any one of them randomly.**"
      ],
      "metadata": {
        "id": "tNMhYtVXkNLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Removing Duplicate Ingredients.**"
      ],
      "metadata": {
        "id": "QdrfUKGJkYP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Coverting list to ingredients to single string of the form which is compatible with the out GPT2 model.**"
      ],
      "metadata": {
        "id": "OdC73Nefkf9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def takeRandomInput():\n",
        "  cdfValues=df['Cdf'].tolist()\n",
        "  ingredientsChoices=[2,3,4,5,6,7,8]\n",
        "  randomNumberOfIngredients=random.choice(ingredientsChoices)\n",
        "  inputIngredientsList=list()\n",
        "  for i in range(0,randomNumberOfIngredients):\n",
        "    currentRandomCdf=random.choice(cdfValues)\n",
        "    currentCdfIngredeintsList=list()\n",
        "    for ind in df1.index:\n",
        "      if(df1['Cdf'][ind]==currentRandomCdf):\n",
        "        currentCdfIngredeintsList.append(df1['ingredient'][ind])\n",
        "    inputIngredientsList.append(random.choice(currentCdfIngredeintsList))\n",
        "\n",
        "  res = []\n",
        "  for i1 in inputIngredientsList:\n",
        "    if i1 not in res:\n",
        "      res.append(i1)\n",
        "\n",
        "  inputIngredientsString=str()\n",
        "  for eachIngredeint in res:\n",
        "    inputIngredientsString=str(eachIngredeint)+str(\",\")+inputIngredientsString\n",
        "  inputIngredientsString=inputIngredientsString[0:len(inputIngredientsString)-1]\n",
        "  inputIngredientsString=inputIngredientsString+str(\";\")\n",
        "  return inputIngredientsString"
      ],
      "metadata": {
        "id": "SoqdLGYCj7fN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building Model Pre-Requisites**"
      ],
      "metadata": {
        "id": "ImOxwhF4kmBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)"
      ],
      "metadata": {
        "id": "of2K2DmTkp_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
        "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
        "        Args:\n",
        "            logits: logits distribution shape (vocabulary size)\n",
        "            top_k > 0: keep only top k tokens with highest probability (top-k filtering).\n",
        "            top_p > 0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
        "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
        "        From: https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317\n",
        "    \"\"\"\n",
        "    assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n",
        "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
        "    if top_k > 0:\n",
        "        # Remove all tokens with a probability less than the last token of the top-k\n",
        "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
        "        logits[indices_to_remove] = filter_value\n",
        "    if top_p > 0.0:\n",
        "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "\n",
        "        # Remove tokens with cumulative probability above the threshold\n",
        "        sorted_indices_to_remove = cumulative_probs > top_p\n",
        "        # Shift the indices to the right to keep also the first token above the threshold\n",
        "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "        sorted_indices_to_remove[..., 0] = 0\n",
        "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "        logits[indices_to_remove] = filter_value\n",
        "    return logits"
      ],
      "metadata": {
        "id": "tKnVNW7Jktrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_sequence(model, length, context, tokenizer, num_samples=1, temperature=1, top_k=0, top_p=0.0, device = 'gpu'):\n",
        "    end_token = tokenizer.convert_tokens_to_ids([\"<END_RECIPE>\"])[0]\n",
        "    context = torch.tensor(context, dtype=torch.long, device=device)\n",
        "    context = context.unsqueeze(0).repeat(num_samples, 1)\n",
        "    generated = context\n",
        "    with torch.no_grad():\n",
        "        for _ in trange(length):\n",
        "            inputs = {'input_ids': generated}\n",
        "            outputs = model(**inputs)  # Note: we could also use 'past' with GPT-2/Transfo-XL/XLNet (cached hidden-states)\n",
        "            next_token_logits = outputs[0][0, -1, :] / temperature\n",
        "            filtered_logits = top_k_top_p_filtering(next_token_logits, top_k=top_k, top_p=top_p)\n",
        "            next_token = torch.multinomial(F.softmax(filtered_logits, dim=-1), num_samples=1)\n",
        "            generated = torch.cat((generated, next_token.unsqueeze(0)), dim=1)\n",
        "            if next_token.item() == end_token:\n",
        "                print('breaking----->>')\n",
        "                break\n",
        "    return generated"
      ],
      "metadata": {
        "id": "vVexaBHslANs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(20)"
      ],
      "metadata": {
        "id": "uT2XUY28lCA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the Method that will generate the Novel recipe by providing the list of Input Ingredients to Trained GPT2 Model**"
      ],
      "metadata": {
        "id": "Vuojh2SllI6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def startRatatouileModel(ingredientsList):\n",
        "  #Prepares model and provides the above random generated ingredients to Ratatouile model  \n",
        "  MODEL_CLASSES = {\n",
        "    'gpt2': (GPT2LMHeadModel, GPT2Tokenizer),\n",
        "  }\n",
        "  MODEL_CLASSES1 = {\n",
        "    'gpt2': (AutoModelWithLMHead, AutoTokenizer),\n",
        "  }\n",
        "  model_class, tokenizer_class = MODEL_CLASSES['gpt2']\n",
        "  tokenizer = tokenizer_class.from_pretrained('tempt')\n",
        "  model = model_class.from_pretrained('tempt')\n",
        "  model.to(torch.device(\"cuda\" ))\n",
        "  model.eval()\n",
        "\n",
        "  raw_text=ingredientsList\n",
        "\n",
        "  prepared_input = '<RECIPE_START> <INPUT_START> ' + raw_text.replace(',', ' <NEXT_INPUT> ').replace(';', ' <INPUT_END>')\n",
        "  context_tokens = tokenizer.encode(prepared_input)\n",
        "\n",
        "  out = sample_sequence(\n",
        "    model=model,\n",
        "    context=context_tokens,\n",
        "    tokenizer=tokenizer,\n",
        "    length=768,\n",
        "    temperature=1,\n",
        "    top_k=30,\n",
        "    top_p=1,\n",
        "    device=torch.device(\"cuda\")\n",
        "  )\n",
        "  out = out[0, len(context_tokens):].tolist()\n",
        "  text = tokenizer.decode(out, clean_up_tokenization_spaces=True)\n",
        "  print(tokenizer.decode)\n",
        "  if \"<RECIPE_END>\" not in text:\n",
        "    print(text)\n",
        "    print(\"Failed to generate, recipe's too long\")\n",
        "  return text, prepared_input"
      ],
      "metadata": {
        "id": "DxsdBb2UlE7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the Final Dataframe that will contain the generated Novel Recipes**"
      ],
      "metadata": {
        "id": "a0-8-L_XlvL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "novelRecipesDataframe=pd.DataFrame(columns=['Random Ingredients', 'Recipe Titile', 'Ingredient Phrases', 'Recipe Instructions'])"
      ],
      "metadata": {
        "id": "v_oegFNTl3IJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the variable that will define how many novel recipes we want to generate using the loop, By default, we are setting it to 10k, change according to your need.**"
      ],
      "metadata": {
        "id": "nnkQThW_l8RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numberOfNovelRecipesNeedsToGenerate=10000"
      ],
      "metadata": {
        "id": "UoEvZwK0mNk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,numberOfNovelRecipesNeedsToGenerate):\n",
        "    randomIngredients=takeRandomInput()\n",
        "   \n",
        "    novelRecipeGenerated,user_input=startRatatouileModel(randomIngredients)\n",
        "    \n",
        "    novelRecipeGenerated = novelRecipeGenerated\n",
        "   \n",
        "    generated_recipe = str(novelRecipeGenerated.replace('<RECIPE_START> <INPUT_START>', '## User inputs ##\\n    -').replace('<NEXT_INPUT>', '\\n    -').replace('<INPUT_END>', '\\n------------------------\\n\\n')\\\n",
        "                        .replace('<TITLE_START>', '## Recipe Name:- ##\\n').replace('<TITLE_END>', '\\n')) \\\n",
        "                        .replace('<INGR_START>', '\\n## Ingredients ##\\n').replace('<NEXT_INGR>', '|').replace('<INGR_END>', '\\n\\n') \\\n",
        "                        .replace('<INSTR_START>', '## Cooking instructions ##\\n').replace('.','.\\n    -').replace(' <NEXT_INSTR>', '. ').replace(' <INSTR_END>', '. ') \\\n",
        "                        .replace(' <RECIPE_END>', '\\n\\n\\n\\nVoila Enjoy your recipe :)\\n\\n\\n\\n\\n -----------\\n')\n",
        "\n",
        "    \n",
        "    idx = generated_recipe.find(\"Voila Enjoy your recipe :)\")\n",
        "    generated_recipe = generated_recipe[0:idx]\n",
        "\n",
        "    rnidx = generated_recipe.find(\"Name:- ##\\n\") # 10 + 1\n",
        "    igidx = generated_recipe.find(\"dients ##\\n\") # 10 \n",
        "    instnidx = generated_recipe.find(\"uctions ##\\n\") # 10 + 1\n",
        "    lastidx = generated_recipe.find(\"\\n\\n\\n\\n\\n\\n\")\n",
        "\n",
        "    randomIngredients = randomIngredients[0:len(randomIngredients)-1]\n",
        "\n",
        "    resname =  generated_recipe[rnidx + 11:igidx-12]\n",
        "    ings = generated_recipe[igidx+10:instnidx-19]\n",
        "    ings = ings.lower()\n",
        "    instn = generated_recipe[instnidx+11:lastidx]\n",
        "\n",
        "    # to add the '-' in between the times like 7-8 minutes\n",
        "    its = instn.split(' ') \n",
        "    for i in range(0, len(its)):\n",
        "      if i < len(its) and its[i].isnumeric() and its[i+1].isnumeric():\n",
        "        its.insert(i+1, \"-\")\n",
        "    instn = \" \".join(its)\n",
        "    \n",
        "\n",
        "    df2={'Random Ingredients': randomIngredients, 'Recipe Titile': resname, 'Ingredient Phrases' : ings, 'Recipe Instructions' : instn}\n",
        "    \n",
        "    novelRecipesDataframe=novelRecipesDataframe.append(df2, ignore_index=True)"
      ],
      "metadata": {
        "id": "HXClGVFDl8p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the Final Dataframe that contains all the Novel Recipes Generated**"
      ],
      "metadata": {
        "id": "pzvv2ZDGmlWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "novelRecipesDataframe.to_csv(\"NovelRecipesGenerated.csv\",index=True)"
      ],
      "metadata": {
        "id": "cYVsNr7OmsX8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}