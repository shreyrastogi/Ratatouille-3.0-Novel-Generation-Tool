{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Downloading, Installing & Importing Required Libraries**"
      ],
      "metadata": {
        "id": "Wrmou4GQ_y_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Packages and Libraries Required for training the model and working with the dataset\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Packages and Libraries Required for implementing Utility/helper functions.\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "import csv\n",
        "import sys\n",
        "import h5py\n",
        "import nltk\n",
        "import math\n",
        "import json\n",
        "import glob\n",
        "import time\n",
        "import torch\n",
        "import shutil\n",
        "import pickle\n",
        "import string\n",
        "import random\n",
        "import pickle\n",
        "import zipfile\n",
        "import pathlib\n",
        "import logging\n",
        "import argparse\n",
        "import platform\n",
        "import itertools\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot\n",
        "from tqdm import tqdm, trange\n",
        "from nltk.stem.porter import *\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.manifold import TSNE\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.decomposition import PCA\n",
        "from transformers import GPT2Tokenizer\n",
        "from keras.layers import Bidirectional\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler\n",
        "from transformers import (WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup, GPT2Config, GPT2LMHeadModel, GPT2Tokenizer)"
      ],
      "metadata": {
        "id": "6C_dtB5nTylQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "QmlHQ0YTWA-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmIdh3Xf_8DH",
        "outputId": "e7d0a914-2262-4f13-8c80-596da0dba957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mounting Google Drive for importing the Data Files which will be used in the Tokenization**"
      ],
      "metadata": {
        "id": "kTts_zswOGQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IGpbSsbJOUu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initializing the WordNet Lemmatizer**"
      ],
      "metadata": {
        "id": "3wQG5kGpVo2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer() "
      ],
      "metadata": {
        "id": "iKkMWtkvVuiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing csv File which contains Unique Recipe IDs**"
      ],
      "metadata": {
        "id": "5g4Kq-naWyfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/RecipeDB_v1/Recipe_correct_ndb_updated_v1.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "k4gNFM8KApMP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "859e64c7-77c1-42e7-d2fd-71efd2581738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         recipe_no                                  ingredient_Phrase  \\\n",
              "0             2610                                       3 cups water   \n",
              "1             2610                                  1 cup red lentils   \n",
              "2             2610                          1 roma tomato , quartered   \n",
              "3             2610                               1 carrot , quartered   \n",
              "4             2610                          1 small onion , quartered   \n",
              "...            ...                                                ...   \n",
              "1154399     149191                                 2 1/2 ounces dates   \n",
              "1154400     149191  9 1/2 9 1/2 ounces three-legume butter ( Recip...   \n",
              "1154401     149191                                 1 teaspoon vanilla   \n",
              "1154402     149191                              1/2 teaspoon cinnamon   \n",
              "1154403     149191                                   1 pinch sea salt   \n",
              "\n",
              "         ingredient      state quantity      unit temp   df   size  ing_id  \\\n",
              "0             water        NaN        3      cups  NaN  NaN    NaN       3   \n",
              "1        red lentil        NaN        1       cup  NaN  NaN    NaN     452   \n",
              "2        rom tomato  quartered        1       NaN  NaN  NaN    NaN     180   \n",
              "3            carrot  quartered        1       NaN  NaN  NaN    NaN      21   \n",
              "4             onion  quartered        1       NaN  NaN  NaN  small       1   \n",
              "...             ...        ...      ...       ...  ...  ...    ...     ...   \n",
              "1154399        date        NaN    2 1/2       1/2  NaN  NaN    NaN     281   \n",
              "1154400      butter     almond    9 1/2    ounces  NaN  NaN    NaN       2   \n",
              "1154401     vanilla        NaN        1  teaspoon  NaN  NaN    NaN      77   \n",
              "1154402    cinnamon        NaN      1/2  teaspoon  NaN  NaN    NaN      15   \n",
              "1154403    sea salt        NaN        1     pinch  NaN  NaN    NaN      90   \n",
              "\n",
              "         ndb_id M_or_A  \n",
              "0         14555      M  \n",
              "1         16144      A  \n",
              "2         93600      A  \n",
              "3         11124      M  \n",
              "4         11282      M  \n",
              "...         ...    ...  \n",
              "1154399    9087      A  \n",
              "1154400   12198      A  \n",
              "1154401    2050      M  \n",
              "1154402   18964      A  \n",
              "1154403   93600      A  \n",
              "\n",
              "[1154404 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-879111aa-c840-4217-8d97-a1c9c90b7c29\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>recipe_no</th>\n",
              "      <th>ingredient_Phrase</th>\n",
              "      <th>ingredient</th>\n",
              "      <th>state</th>\n",
              "      <th>quantity</th>\n",
              "      <th>unit</th>\n",
              "      <th>temp</th>\n",
              "      <th>df</th>\n",
              "      <th>size</th>\n",
              "      <th>ing_id</th>\n",
              "      <th>ndb_id</th>\n",
              "      <th>M_or_A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2610</td>\n",
              "      <td>3 cups water</td>\n",
              "      <td>water</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>cups</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>14555</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2610</td>\n",
              "      <td>1 cup red lentils</td>\n",
              "      <td>red lentil</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>cup</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>452</td>\n",
              "      <td>16144</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2610</td>\n",
              "      <td>1 roma tomato , quartered</td>\n",
              "      <td>rom tomato</td>\n",
              "      <td>quartered</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>180</td>\n",
              "      <td>93600</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2610</td>\n",
              "      <td>1 carrot , quartered</td>\n",
              "      <td>carrot</td>\n",
              "      <td>quartered</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21</td>\n",
              "      <td>11124</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2610</td>\n",
              "      <td>1 small onion , quartered</td>\n",
              "      <td>onion</td>\n",
              "      <td>quartered</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>small</td>\n",
              "      <td>1</td>\n",
              "      <td>11282</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1154399</th>\n",
              "      <td>149191</td>\n",
              "      <td>2 1/2 ounces dates</td>\n",
              "      <td>date</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2 1/2</td>\n",
              "      <td>1/2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>281</td>\n",
              "      <td>9087</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1154400</th>\n",
              "      <td>149191</td>\n",
              "      <td>9 1/2 9 1/2 ounces three-legume butter ( Recip...</td>\n",
              "      <td>butter</td>\n",
              "      <td>almond</td>\n",
              "      <td>9 1/2</td>\n",
              "      <td>ounces</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>12198</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1154401</th>\n",
              "      <td>149191</td>\n",
              "      <td>1 teaspoon vanilla</td>\n",
              "      <td>vanilla</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>teaspoon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>77</td>\n",
              "      <td>2050</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1154402</th>\n",
              "      <td>149191</td>\n",
              "      <td>1/2 teaspoon cinnamon</td>\n",
              "      <td>cinnamon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1/2</td>\n",
              "      <td>teaspoon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15</td>\n",
              "      <td>18964</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1154403</th>\n",
              "      <td>149191</td>\n",
              "      <td>1 pinch sea salt</td>\n",
              "      <td>sea salt</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>pinch</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>90</td>\n",
              "      <td>93600</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1154404 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-879111aa-c840-4217-8d97-a1c9c90b7c29')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-879111aa-c840-4217-8d97-a1c9c90b7c29 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-879111aa-c840-4217-8d97-a1c9c90b7c29');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fetching Unique Recipe IDs**"
      ],
      "metadata": {
        "id": "EH1zsAkGW5sV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recipeIds=list(df['recipe_no'].unique())\n",
        "print(recipeIds)\n",
        "recipeIdslistStringForm=list()\n",
        "for eachRecipeId in recipeIds:\n",
        "  recipeIdslistStringForm.append(str(eachRecipeId))"
      ],
      "metadata": {
        "id": "fGF5O1kZA3Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Displaying the Number of Unique Recipe Ids**"
      ],
      "metadata": {
        "id": "c1OL5BvsXBcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of Unique Recipe Ids:\",len(recipeIdslistStringForm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jenBkWkVA8a4",
        "outputId": "d1d45d48-3afa-4c7d-bca2-98af4c36563f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Unique Recipe Ids: 118083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing json File which contains Recipe Ids with thier Instructions**"
      ],
      "metadata": {
        "id": "z_LfElkZXkKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Final_Model_Rata2_Recipegen/recipe_db_data.json\") as data_file:\n",
        "    data = json.load(data_file)"
      ],
      "metadata": {
        "id": "glWXzR14BCdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing Recipe IDs from json data which are Not Present in Unique Recipe Ids csv file**"
      ],
      "metadata": {
        "id": "Ofo_Tl8nXwZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in enumerate(data):\n",
        "  if y['Recipe_id'] not in recipeIdslistStringForm:\n",
        "    data.pop(x)"
      ],
      "metadata": {
        "id": "G0FIsPSxA-C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the Generated json file which Contains same Unique Recipes**"
      ],
      "metadata": {
        "id": "VOTHz0UpX6PM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"data_v1.json\", \"w\") as final:\n",
        "    json.dump(data, final)\n",
        "files.download('data_v1.json')"
      ],
      "metadata": {
        "id": "y5B0ePVWVxWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-Processing Steps Start from Here**"
      ],
      "metadata": {
        "id": "aQwH7V5aYF3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Opening the json file that was Dumped above**"
      ],
      "metadata": {
        "id": "6C1hkHwVYMCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/data_v1.json')\n",
        "data_new = json.load(f)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "XgQVevejkArL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Displaying the Total Number of Recipes**"
      ],
      "metadata": {
        "id": "Uvzd17KCYe16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Number of Recipes are: \",len(data_new))"
      ],
      "metadata": {
        "id": "3FwYgsNcleg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the function to perform Ingredients Merging to the corresponding Recipe IDs and their instruction**"
      ],
      "metadata": {
        "id": "JlWNUuTFYpXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(ingredients_path,steps_path, title_path):\n",
        "    print(\"Loading all required files..\\n\")\n",
        "    df_titles = pd.read_csv(title_path)\n",
        "    ingredients = pd.read_csv(ingredients_path)\n",
        "    with open(steps_path) as json_file: \n",
        "        steps = json.load(json_file) \n",
        "\n",
        "    print(\"\\n\\nCreating steps dict..\\n\")\n",
        "    steps_dic = {}\n",
        "    for dic in steps:\n",
        "        steps_dic[int(dic['Recipe_id'])] = dic['steps'].split(';')\n",
        "\n",
        "    print(\"\\n\\nCreating title dict..\\n\")\n",
        "    recipe_ids = []\n",
        "    recipe_ids = df_titles['Recipe_id'].tolist()\n",
        "    titles = df_titles['Recipe_title'].tolist()\n",
        "    continents = df_titles['Continent'].tolist()\n",
        "    regions = df_titles['Region'].tolist()\n",
        "    sub_region = df_titles['Sub_region'].tolist()\n",
        "    title_dic = {}\n",
        "    continet_dict = {}\n",
        "    region_dict = {}\n",
        "    sub_region_dict = {}\n",
        "\n",
        "    for i in range(len(titles)):\n",
        "      if recipe_ids[i] not in title_dic:\n",
        "        title_dic[recipe_ids[i]]=titles[i]\n",
        "        continet_dict[recipe_ids[i]] = continents[i]\n",
        "        region_dict[recipe_ids[i]] = regions[i]\n",
        "        sub_region_dict[recipe_ids[i]] = sub_region[i]\n",
        "    \n",
        "    print(\"\\n\\nCreating ingredients dict..\\n\")\n",
        "    recipe_ids = []\n",
        "    recipe_ids = ingredients['recipe_no'].tolist()\n",
        "    ing = ingredients['ingredient'].tolist()\n",
        "    ing_phrase = ingredients['ingredient_Phrase'].tolist()\n",
        "\n",
        "    ingredient_dic = {}\n",
        "    for i in range(len(recipe_ids)):\n",
        "        ingredient_dic[recipe_ids[i]] = []\n",
        "    for i in range(len(ing)):\n",
        "        if str(ing[i]) != 'nan':\n",
        "            ingredient_dic[recipe_ids[i]].append(ing[i])\n",
        "    \n",
        "    ing_phrase_dic = {}\n",
        "    for i in range(len(recipe_ids)):\n",
        "        ing_phrase_dic[recipe_ids[i]] = []\n",
        "    for i in range(len(ing_phrase)):\n",
        "        if str(ing_phrase[i]) != 'nan':\n",
        "            ing_phrase_dic[recipe_ids[i]].append(ing_phrase[i])\n",
        "\n",
        "    print(\"\\nCreating data and validating..\\n\")\n",
        "    dataset = []\n",
        "    recipe_ids =  list(set(ingredients['recipe_no'].tolist()))\n",
        "    \n",
        "    for i in recipe_ids:\n",
        "      recipe = {}\n",
        "      recipe['ID'] = i\n",
        "      try:\n",
        "        recipe['title'] = title_dic[i]\n",
        "        recipe['ingredients'] = ingredient_dic[i]\n",
        "        recipe['ingredient_phrase'] = ing_phrase_dic[i]\n",
        "        recipe['continent'] = continet_dict[i]\n",
        "        recipe['region'] = region_dict[i]\n",
        "        recipe['sub_region'] = sub_region_dict[i]\n",
        "        recipe['instructions'] = steps_dic[i]\n",
        "\n",
        "      except KeyError:\n",
        "        continue\n",
        "        \n",
        "      if len(recipe['title']) != 0 and len(recipe['instructions']) != 0 and len(recipe['ingredients']) != 0:\n",
        "          dataset.append(recipe)\n",
        "    \n",
        "    print(\"\\n COMPLETED\")\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "W_mlLNR3Xf_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the Path of the Files required for performing the Merging Operation**"
      ],
      "metadata": {
        "id": "K5pb6rQxZMez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps_path = '/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/data_v1.json'\n",
        "titles_path = '/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/Recipes(6).csv'\n",
        "ingredients_path = '/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/RecipeDB_v1/Recipe_correct_ndb_updated_v1.csv'"
      ],
      "metadata": {
        "id": "GXmb3iglX2sC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calling the above method for Performing the corresponding operation**"
      ],
      "metadata": {
        "id": "WaWF95zmZcxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_dataset(ingredients_path,steps_path, titles_path)"
      ],
      "metadata": {
        "id": "tErmqBIbYMl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Displaying the Single Recipe Data to Analyze and Decide what Pre-Processing steps should be applied on the Recipes Data**"
      ],
      "metadata": {
        "id": "bagW_rEWZjqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esRecoK1ZBzD",
        "outputId": "ffc52384-2449-464a-c474-24862a93835b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ID': 2610,\n",
              " 'title': 'Egyptian Lentil Soup',\n",
              " 'ingredients': ['water',\n",
              "  'red lentil',\n",
              "  'rom tomato',\n",
              "  'carrot',\n",
              "  'onion',\n",
              "  'garlic',\n",
              "  'cumin',\n",
              "  'sea salt',\n",
              "  'black pepper',\n",
              "  'coriander'],\n",
              " 'ingredient_phrase': ['3 cups water',\n",
              "  '1 cup red lentils',\n",
              "  '1 roma tomato , quartered',\n",
              "  '1 carrot , quartered',\n",
              "  '1 small onion , quartered',\n",
              "  '4 cloves garlic , quartered',\n",
              "  '2 teaspoons ground cumin',\n",
              "  '1/2 teaspoon sea salt',\n",
              "  '1/2 teaspoon cracked black pepper',\n",
              "  '1/4 teaspoon ground coriander'],\n",
              " 'continent': 'African',\n",
              " 'region': 'Middle Eastern',\n",
              " 'sub_region': 'Egyptian',\n",
              " 'instructions': [' | 1.\\tPlace 3 cups water, lentils, tomato, carrot, onion, garlic, and chicken bouillon in a stockpot over medium heat',\n",
              "  ' cook until vegetables and lentils are softened, 20 to 25 minutes. Remove from heat and cool to lukewarm. | 2.\\tBlend vegetable and lentil mixture with an immersion blender until smooth. Stir 1 cup water, cumin, sea salt, pepper, and coriander into soup',\n",
              "  ' heat over medium heat until warmed. | ---------------------------------------------------------------------------']}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Pre-Processing Methods and Applying them on the Recipe Data**"
      ],
      "metadata": {
        "id": "OuhzNQTdZ9Sk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method to Lemmatize the Ingredients of the Recipe**"
      ],
      "metadata": {
        "id": "Cj-9a4YtbwN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_ingredients(l):\n",
        "  l = [ele.lower() for ele in l]\n",
        "  l = [ lemmatizer.lemmatize(ele) for ele in l]\n",
        "  l =  set(l)\n",
        "  l = list(l)\n",
        "  return l\n",
        "\n",
        "for i in range(len(data)):\n",
        "  ing = data[i]['ingredients']\n",
        "  ing_fix = clean_ingredients(ing)\n",
        "  data[i]['ingredients'] = ing_fix "
      ],
      "metadata": {
        "id": "n-kW27OWZMEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method to Fix the Punctuation of the Instructions of the Recipes**"
      ],
      "metadata": {
        "id": "t2cgjj7Xb2tL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_punctuation(l):\n",
        "  newl = []\n",
        "  for i in range(len(l)):\n",
        "    x = re.sub(r'\\s([?.!\",](?:\\s|$))', r'\\1', l[i])\n",
        "    newl.append(x)\n",
        "  return newl\n",
        "\n",
        "punc_fix_data = []\n",
        "for i in range(len(data)):\n",
        "  ins = data[i]['instructions']\n",
        "  ins_fix = fix_punctuation(ins)\n",
        "  data[i]['instructions'] = ins_fix "
      ],
      "metadata": {
        "id": "K2YztborZgCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method to Capitalize and Removing the Extra space at start of the Instructions of the Recipe**"
      ],
      "metadata": {
        "id": "qVOuX6P2cGqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = re.compile(r'((?<=[\\.\\?!]\\s)(\\w+)|(^\\w+)|(^\\w*))')\n",
        "def cap(match):\n",
        "    return(match.group().capitalize())\n",
        "\n",
        "def fix_caps(l):\n",
        "  newl = []\n",
        "  for i in range(len(l)):\n",
        "    a = l[i].lstrip()\n",
        "    y = p.sub(cap, a)\n",
        "    newl.append(y)\n",
        "  return newl\n",
        "\n",
        "\n",
        "for i in range(len(data)):\n",
        "  ins = data[i]['instructions']\n",
        "  ins_caps = fix_caps(ins)\n",
        "  data[i]['instructions'] = ins_caps"
      ],
      "metadata": {
        "id": "5R5GxHa6Zj0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Displaying the Single Recipe Data after Applying the above Pre-Processing Methods**"
      ],
      "metadata": {
        "id": "rSp8g07Na0Bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ymvc8tKIZo99",
        "outputId": "ba5db86f-5722-4a2b-99b2-4fbdc32180a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ID': 2610,\n",
              " 'title': 'Egyptian Lentil Soup',\n",
              " 'ingredients': ['onion',\n",
              "  'rom tomato',\n",
              "  'sea salt',\n",
              "  'water',\n",
              "  'cumin',\n",
              "  'garlic',\n",
              "  'coriander',\n",
              "  'carrot',\n",
              "  'red lentil',\n",
              "  'black pepper'],\n",
              " 'ingredient_phrase': ['3 cups water',\n",
              "  '1 cup red lentils',\n",
              "  '1 roma tomato , quartered',\n",
              "  '1 carrot , quartered',\n",
              "  '1 small onion , quartered',\n",
              "  '4 cloves garlic , quartered',\n",
              "  '2 teaspoons ground cumin',\n",
              "  '1/2 teaspoon sea salt',\n",
              "  '1/2 teaspoon cracked black pepper',\n",
              "  '1/4 teaspoon ground coriander'],\n",
              " 'continent': 'African',\n",
              " 'region': 'Middle Eastern',\n",
              " 'sub_region': 'Egyptian',\n",
              " 'instructions': ['| 1.\\tPlace 3 cups water, lentils, tomato, carrot, onion, garlic, and chicken bouillon in a stockpot over medium heat',\n",
              "  'Cook until vegetables and lentils are softened, 20 to 25 minutes. Remove from heat and cool to lukewarm. | 2.\\tBlend vegetable and lentil mixture with an immersion blender until smooth. Stir 1 cup water, cumin, sea salt, pepper, and coriander into soup',\n",
              "  'Heat over medium heat until warmed. | ---------------------------------------------------------------------------']}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Placing '.' (full stop) after instructions which do not end with the '.' (full stop)**"
      ],
      "metadata": {
        "id": "oFIl3CdDbDdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(data)):\n",
        "  ins = data[i]['instructions']\n",
        "  for j in range(len(ins)):\n",
        "    if(ins[j].endswith('.')):\n",
        "      continue\n",
        "    else:\n",
        "      ins[j] = ins[j].rstrip()\n",
        "      ins[j]=ins[j]+\".\""
      ],
      "metadata": {
        "id": "7izAsx_jZuiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the Final Pre-Processed File**"
      ],
      "metadata": {
        "id": "zwxsCBe3bhca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/data_v1.pickle', 'wb') as handle:\n",
        "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "c6vCddBXZyOd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
