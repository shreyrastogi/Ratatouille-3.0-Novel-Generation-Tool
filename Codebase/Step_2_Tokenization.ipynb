{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Installing & Importing Required Libraries**"
      ],
      "metadata": {
        "id": "GWZkPIPuNfTy"
      },
      "id": "GWZkPIPuNfTy"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "v2TsjoGERiZq"
      },
      "id": "v2TsjoGERiZq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import h5py\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib as jb\n",
        "from transformers import GPT2Tokenizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "aRvuXwcgNpew"
      },
      "id": "aRvuXwcgNpew",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mounting Google Drive for importing the Data Files which will be used in the Tokenization**"
      ],
      "metadata": {
        "id": "kTts_zswOGQ7"
      },
      "id": "kTts_zswOGQ7"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IGpbSsbJOUu5"
      },
      "id": "IGpbSsbJOUu5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Updated Recipe json File which contains Recipe Data**"
      ],
      "metadata": {
        "id": "qYIm1rnBN4nn"
      },
      "id": "qYIm1rnBN4nn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weird-allergy"
      },
      "outputs": [],
      "source": [
        "df_new = jb.load('/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/data_v1.pickle')"
      ],
      "id": "weird-allergy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting Recipe json File into a DataFrame**"
      ],
      "metadata": {
        "id": "m8pB2zjZObzR"
      },
      "id": "m8pB2zjZObzR"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(df_new)"
      ],
      "metadata": {
        "id": "d8uaLCjDq9cC"
      },
      "execution_count": null,
      "outputs": [],
      "id": "d8uaLCjDq9cC"
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "QrZYQ2tirGZE"
      },
      "execution_count": null,
      "outputs": [],
      "id": "QrZYQ2tirGZE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Formatting the Instructions of the Recipe by Performing operations like removing '\\t' from the beginning of the instructions, inserting ';' at the end of each instruction, etc**"
      ],
      "metadata": {
        "id": "mi5qNn5xOvjc"
      },
      "id": "mi5qNn5xOvjc"
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_instrns = []\n",
        "for row in range(0,len(df)):\n",
        "    instr = df.iloc[row]['instructions']\n",
        "    \n",
        "    strg = \"\"\n",
        "    length = len(instr) - 1\n",
        "    count = 0\n",
        "    for instruction in instr:\n",
        "        processed_instr = []\n",
        "        for j in range(0,len(instruction)):\n",
        "            if(instruction[j]=='|' or instruction[j]=='\\t'):\n",
        "                continue\n",
        "            elif(instruction[j]==' '):\n",
        "                if(instruction[j-1]!='|'):\n",
        "                   strg = strg + instruction[j]\n",
        "            elif(instruction[j] == '.') and (j!=len(instruction)-1) and (instruction[j-1].isdigit()==False):\n",
        "                strg = strg + ' '\n",
        "                strg = strg + instruction[j]      \n",
        "            elif(instruction[j]>='a' and instruction[j]<='z') or (instruction[j]>='A' and instruction[j]<='Z') :\n",
        "                 strg =  strg + instruction[j].lower()\n",
        "            elif(instruction[j] == ','):\n",
        "                  strg =  strg + ' '\n",
        "                  strg =  strg + ',' \n",
        "            elif(instruction[j].isdigit()):\n",
        "                if(instruction[j+1] == '.') or (instruction[j+2] == '.'):\n",
        "                    continue\n",
        "                else:\n",
        "                    strg = strg + instruction[j]  \n",
        "                     \n",
        "        if(count!=length):        \n",
        "            strg = strg + ' '\n",
        "            strg = strg + ';' \n",
        "            strg = strg + ' '\n",
        "  \n",
        "   \n",
        "        count = count + 1     \n",
        "          \n",
        "    processed_instr.append(strg)\n",
        "    list_of_instrns.append(processed_instr)      "
      ],
      "metadata": {
        "id": "6liGcp0Vz0aL"
      },
      "execution_count": null,
      "outputs": [],
      "id": "6liGcp0Vz0aL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deleting the current \"instructions\" column from the DataFrame and inserting the modified Instructions by Creating the new \"instructions\" column**"
      ],
      "metadata": {
        "id": "MTRskfyTPZqK"
      },
      "id": "MTRskfyTPZqK"
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('instructions', inplace=True, axis=1)"
      ],
      "metadata": {
        "id": "thBlxEbU2esx"
      },
      "execution_count": null,
      "outputs": [],
      "id": "thBlxEbU2esx"
    },
    {
      "cell_type": "code",
      "source": [
        "df['instructions'] = list_of_instrns"
      ],
      "metadata": {
        "id": "6z0mlsfx2kmz"
      },
      "execution_count": null,
      "outputs": [],
      "id": "6z0mlsfx2kmz"
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "FxkhruF-2sll",
        "outputId": "56b375dc-ba48-4976-baf7-a3d9d2a3dd07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     ID                              title  \\\n",
              "0  2610               Egyptian Lentil Soup   \n",
              "1  2611  Egyptian Green Beans with Carrots   \n",
              "2  2612                     Egyptian Bamia   \n",
              "3  2613        Magpie's Easy Falafel Cakes   \n",
              "4  2614                             Dukkah   \n",
              "\n",
              "                                         ingredients  \\\n",
              "0  [onion, rom tomato, sea salt, water, cumin, ga...   \n",
              "1  [onion, chicken stock, tomato paste, cardamom,...   \n",
              "2  [onion, lamb shoulder, olive oil, water, okra,...   \n",
              "3  [onion, salt, cornmeal, olive oil, cumin, sauc...   \n",
              "4  [sesame seed, hazelnut, sea salt, coriander se...   \n",
              "\n",
              "                                   ingredient_phrase continent  \\\n",
              "0  [3 cups water, 1 cup red lentils, 1 roma tomat...   African   \n",
              "1  [1 tablespoon vegetable oil, 1 large onion , d...   African   \n",
              "2  [1/4 cup olive oil, 1 large onion , finely cho...   African   \n",
              "3  [1/2 small onion , minced, 1 1/2 teaspoons oli...   African   \n",
              "4  [2/3 cup hazelnuts, 1/2 cup sesame seeds, 2 ta...   African   \n",
              "\n",
              "           region sub_region  \\\n",
              "0  Middle Eastern   Egyptian   \n",
              "1  Middle Eastern   Egyptian   \n",
              "2  Middle Eastern   Egyptian   \n",
              "3  Middle Eastern   Egyptian   \n",
              "4  Middle Eastern   Egyptian   \n",
              "\n",
              "                                        instructions  \n",
              "0  [place 3 cups water , lentils , tomato , carro...  \n",
              "1  [heat oil in a pot over medium heat ; cook and...  \n",
              "2  [heat olive oil in a large saucepan over mediu...  \n",
              "3  [cook the onions in 1 12 teaspoons of olive oi...  \n",
              "4  [preheat the oven to 350 degrees f 175 degrees...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17c41786-4d6d-441a-b3bb-6bd2693b2836\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>title</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>ingredient_phrase</th>\n",
              "      <th>continent</th>\n",
              "      <th>region</th>\n",
              "      <th>sub_region</th>\n",
              "      <th>instructions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2610</td>\n",
              "      <td>Egyptian Lentil Soup</td>\n",
              "      <td>[onion, rom tomato, sea salt, water, cumin, ga...</td>\n",
              "      <td>[3 cups water, 1 cup red lentils, 1 roma tomat...</td>\n",
              "      <td>African</td>\n",
              "      <td>Middle Eastern</td>\n",
              "      <td>Egyptian</td>\n",
              "      <td>[place 3 cups water , lentils , tomato , carro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2611</td>\n",
              "      <td>Egyptian Green Beans with Carrots</td>\n",
              "      <td>[onion, chicken stock, tomato paste, cardamom,...</td>\n",
              "      <td>[1 tablespoon vegetable oil, 1 large onion , d...</td>\n",
              "      <td>African</td>\n",
              "      <td>Middle Eastern</td>\n",
              "      <td>Egyptian</td>\n",
              "      <td>[heat oil in a pot over medium heat ; cook and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2612</td>\n",
              "      <td>Egyptian Bamia</td>\n",
              "      <td>[onion, lamb shoulder, olive oil, water, okra,...</td>\n",
              "      <td>[1/4 cup olive oil, 1 large onion , finely cho...</td>\n",
              "      <td>African</td>\n",
              "      <td>Middle Eastern</td>\n",
              "      <td>Egyptian</td>\n",
              "      <td>[heat olive oil in a large saucepan over mediu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2613</td>\n",
              "      <td>Magpie's Easy Falafel Cakes</td>\n",
              "      <td>[onion, salt, cornmeal, olive oil, cumin, sauc...</td>\n",
              "      <td>[1/2 small onion , minced, 1 1/2 teaspoons oli...</td>\n",
              "      <td>African</td>\n",
              "      <td>Middle Eastern</td>\n",
              "      <td>Egyptian</td>\n",
              "      <td>[cook the onions in 1 12 teaspoons of olive oi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2614</td>\n",
              "      <td>Dukkah</td>\n",
              "      <td>[sesame seed, hazelnut, sea salt, coriander se...</td>\n",
              "      <td>[2/3 cup hazelnuts, 1/2 cup sesame seeds, 2 ta...</td>\n",
              "      <td>African</td>\n",
              "      <td>Middle Eastern</td>\n",
              "      <td>Egyptian</td>\n",
              "      <td>[preheat the oven to 350 degrees f 175 degrees...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17c41786-4d6d-441a-b3bb-6bd2693b2836')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17c41786-4d6d-441a-b3bb-6bd2693b2836 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17c41786-4d6d-441a-b3bb-6bd2693b2836');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "id": "FxkhruF-2sll"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dividing whole Data into Train and Test part with the Ratio of Train to Test is 0.96 : 0.04**"
      ],
      "metadata": {
        "id": "ziMwJ9oKPttI"
      },
      "id": "ziMwJ9oKPttI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "reserved-heavy",
      "metadata": {
        "id": "reserved-heavy"
      },
      "outputs": [],
      "source": [
        "train,test = train_test_split(df, train_size=0.96, random_state= 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Displaying the Size of Train and Test Part and Resetting to the Default Index of these portions**"
      ],
      "metadata": {
        "id": "BIo4YvmTQGSl"
      },
      "id": "BIo4YvmTQGSl"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Portion size is: \",train.shape)\n",
        "print(\"Test Portion size is: \",test.shape)"
      ],
      "metadata": {
        "id": "iT38CTW2QL0h"
      },
      "id": "iT38CTW2QL0h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "retired-allen",
      "metadata": {
        "id": "retired-allen"
      },
      "outputs": [],
      "source": [
        "train.reset_index(drop=True, inplace=True)\n",
        "test.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the function that will be used for Converting the Dataset into Text Data Format so that the the Data can be Tokenize**"
      ],
      "metadata": {
        "id": "liQi9K8dQrQg"
      },
      "id": "liQi9K8dQrQg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "removed-trailer",
      "metadata": {
        "id": "removed-trailer"
      },
      "outputs": [],
      "source": [
        "def df_to_plaintext_file(input_df, output_file):\n",
        "    print(\"Writing to\", output_file)\n",
        "    with open(output_file, 'w', encoding=\"utf-8\") as f:\n",
        "        for index, row in input_df.iterrows():\n",
        "            title = row.title\n",
        "            instructions = row.instructions[0].split('.')[:-1]\n",
        "            ingredients = row.ingredient_phrase\n",
        "            keyword = row.ingredients\n",
        "            \n",
        "            if index%40000==0:\n",
        "                print(index)\n",
        "                print(\"ingreds --->\",ingredients)\n",
        "                print(\"keywords --->\",keyword)\n",
        "\n",
        "            res = \"<RECIPE_START> <INPUT_START> \" + \" <NEXT_INPUT> \".join(keyword) + \" <INPUT_END> <TITLE_START> \" + \\\n",
        "              title + \"<TITLE_END> <INGR_START> \" + \\\n",
        "              \" <NEXT_INGR> \".join(ingredients) + \" <INGR_END> <INSTR_START> \" + \" <NEXT_INSTR> \".join(instructions) + \" <INSTR_END> <RECIPE_END>\"\n",
        "            f.write(\"{}\\n\".format(res))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the Processed Train and Test Files to the Custom Path**"
      ],
      "metadata": {
        "id": "NO7p7NoCRGCY"
      },
      "id": "NO7p7NoCRGCY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "historic-scanner",
      "metadata": {
        "id": "historic-scanner"
      },
      "outputs": [],
      "source": [
        "df_to_plaintext_file(train, '/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/train_temp.txt')\n",
        "df_to_plaintext_file(test, '/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/test_temp.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initializing the GPT2 Tokenizer and Adding special Tokens defined by us to Define the different parts of the Recipe like its title, constituting ingredeints, etc**"
      ],
      "metadata": {
        "id": "OP_F-goqRz1S"
      },
      "id": "OP_F-goqRz1S"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "outer-extent",
      "metadata": {
        "id": "outer-extent"
      },
      "outputs": [],
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", do_lower_case=False)\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
        "special_tokens = {\n",
        "    \"additional_special_tokens\": ['<RECIPE_START>',\n",
        "                                  '<INPUT_START>',\n",
        "                                  '<NEXT_INPUT>',\n",
        "                                  '<INPUT_END>',\n",
        "                                  '<INGR_START>',\n",
        "                                  '<NEXT_INGR>',\n",
        "                                  '<INGR_END>',\n",
        "                                  '<INSTR_START>',\n",
        "                                  '<NEXT_INSTR>',\n",
        "                                  '<INSTR_END>',\n",
        "                                  '<TITLE_START>'\n",
        "                                  ,'<TITLE_END>'\n",
        "                                  ,'<RECIPE_END>'\n",
        "    ]\n",
        "}\n",
        "\n",
        "tokenizer.add_special_tokens(special_tokens)\n",
        "\n",
        "end_token_id = tokenizer.convert_tokens_to_ids([\"<RECIPE_END>\"])[0]\n",
        "\n",
        "hf = h5py.File(\"/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/data_temp.h5\", \"w\")\n",
        "for filename in [\"/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/test_temp\", \"/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/train_temp\"]:\n",
        "    out_np = []\n",
        "    data = open(filename+\".txt\", \"r\")\n",
        "    num = 0\n",
        "    rows = 0\n",
        "    last=[]\n",
        "    for line in data:\n",
        "        num+=1\n",
        "        if num%10000 == 0:\n",
        "            print(\"Read \"+str(num)+\" Written: \"+str(rows))\n",
        "\n",
        "        text_tokens = tokenizer.tokenize(line) \n",
        "        # the tokens supported by gpt2 are 1024 for gpt2 medium. so if the recipe is exceeds this length it wont fit in the model and will generate errors. \n",
        "        if len(text_tokens) > 1024: \n",
        "            continue\n",
        "\n",
        "        text_tokens_ids = tokenizer.convert_tokens_to_ids(text_tokens)\n",
        "\n",
        "        if (len(last) + len(text_tokens_ids)) <= 1024:\n",
        "            last+=text_tokens_ids\n",
        "        else:\n",
        "            while len(last) < 1024:\n",
        "                last.append(end_token_id)\n",
        "            out_np.append(last)\n",
        "            last=text_tokens_ids\n",
        "            rows+=1\n",
        "    out_mat = np.matrix(out_np)\n",
        "    print(out_mat.shape)\n",
        "    hf.create_dataset(filename, data=out_mat)\n",
        "hf.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Displaying the Final Length of Tokenizer**"
      ],
      "metadata": {
        "id": "Hd-jXC4BSUBB"
      },
      "id": "Hd-jXC4BSUBB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "genuine-production",
      "metadata": {
        "id": "genuine-production",
        "outputId": "8f625620-8603-4887-a5fd-8a04b802d485",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50270"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "len(tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Displaying the Final Number of Recipes Downsampled**"
      ],
      "metadata": {
        "id": "4FpGaVCFSfV6"
      },
      "id": "4FpGaVCFSfV6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cheap-organ",
      "metadata": {
        "id": "cheap-organ"
      },
      "outputs": [],
      "source": [
        "t = []\n",
        "with open('/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/train_temp.txt') as file1:\n",
        "    for f in file1:\n",
        "        t.append(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "usual-technical",
      "metadata": {
        "id": "usual-technical",
        "outputId": "ac84d426-dddb-4156-ccae-5794fd42ff5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of recipes downsampled for prototyping:  113359\n"
          ]
        }
      ],
      "source": [
        "print('No of recipes downsampled for prototyping: ',len(t))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.7rc1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7rc1"
    },
    "vscode": {
      "interpreter": {
        "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
