{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrDC5mrPMPs9"
      },
      "source": [
        "**Downloading, Installing & Importing Required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AWfpdZHMPtB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import h5py\n",
        "import math\n",
        "import torch\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "UgIkZWuxMgoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDF9T1lQMPtC"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelWithLMHead,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    PreTrainedTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    set_seed,\n",
        "    TrainerCallback\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mounting Google Drive for importing the Data Files which will be used in the Tokenization**"
      ],
      "metadata": {
        "id": "kTts_zswOGQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IGpbSsbJOUu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5ryr_toMPtD"
      },
      "source": [
        "**Selecting the GPU to Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIvF7f78MPtD"
      },
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd1Tl5eYMPtD"
      },
      "source": [
        "**Defining the Method that will Create the Pytorch Compatible Dataset Class** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCE1UWRfMPtE"
      },
      "outputs": [],
      "source": [
        "class H5Dataset(Dataset):\n",
        "    def __init__(self, tokenizer, file_path='/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/train_temp', block_size=512): \n",
        "        cached_features_file = \"/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/data_temp.h5\"\n",
        "\n",
        "        # logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
        "        print((\"Loading features from cached file %s\", cached_features_file))\n",
        "        with h5py.File(cached_features_file, 'r') as f:\n",
        "            if file_path=='/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/test_temp':\n",
        "                self.samples = f[file_path][:] #this is a dev set, 30% of a test set\n",
        "            else:\n",
        "                self.samples = f[file_path][:]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return torch.tensor(self.samples[item]) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset( tokenizer, evaluate=False, local_rank=-1):\n",
        "  file_path = \"/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/test_temp\" if evaluate else \"/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/train_temp\"\n",
        "  return H5Dataset(tokenizer=tokenizer, file_path=file_path)"
      ],
      "metadata": {
        "id": "cCJYvMaesBuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38EX9P5HMPtE"
      },
      "source": [
        "**Performing Transformer Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJfrDKrqMPtF"
      },
      "outputs": [],
      "source": [
        "config = AutoConfig.from_pretrained('gpt2', cache_dir='cache')\n",
        "set_seed(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFms76PUMPtF"
      },
      "source": [
        "**Defining the Tokenizer for the Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QExSKfsMPtG"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('gpt2', cache_dir= 'cache')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLwlyQ90MPtG"
      },
      "source": [
        "**Initialising the GPT2 Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hNhBNfrMPtG"
      },
      "outputs": [],
      "source": [
        "model = AutoModelWithLMHead.from_pretrained('gpt2',config=config,cache_dir='cache',)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er9hqgA3MPtG"
      },
      "source": [
        "**Adding the Special Recipe Token to the Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMkUJgfvMPtH"
      },
      "outputs": [],
      "source": [
        "special_tokens = {\n",
        "    \"additional_special_tokens\": ['<RECIPE_START>',\n",
        "                                  '<INPUT_START>',\n",
        "                                  '<NEXT_INPUT>',\n",
        "                                  '<INPUT_END>',\n",
        "                                  '<INGR_START>',\n",
        "                                  '<NEXT_INGR>',\n",
        "                                  '<INGR_END>',\n",
        "                                  '<INSTR_START>',\n",
        "                                  '<NEXT_INSTR>',\n",
        "                                  '<INSTR_END>',\n",
        "                                  '<TITLE_START>'\n",
        "                                  ,'<TITLE_END>'\n",
        "                                  ,'<RECIPE_END>'\n",
        "        ]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resizeing the Model to Fit the Tokenizer with Special Tokens**"
      ],
      "metadata": {
        "id": "fMco4uwafaz7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8IVNRNuMPtH"
      },
      "outputs": [],
      "source": [
        "tokenizer.add_special_tokens(special_tokens)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting the Train and Validation Dataset to Pytorch Dataset so as it can be given to the Model as Input for Training**"
      ],
      "metadata": {
        "id": "gPvLc4kzflAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = (get_dataset(tokenizer=tokenizer))\n",
        "eval_dataset = (get_dataset(tokenizer=tokenizer, evaluate=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBzqevk4s0fi",
        "outputId": "6a8f1524-91d7-41da-df0e-2c7a0e7e1843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Loading features from cached file %s', '/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/data_temp.h5')\n",
            "('Loading features from cached file %s', '/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/data_temp.h5')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To be able to build batches, data collators may apply some processing (like padding).Some of them (like DataCollatorForLanguageModeling) also apply some random data augmentation (like random masking) oin the formed batch.\n",
        "Data collators are objects that will form a batch by using a list of dataset elements as input. These elements are of the same type as the elements of train_dataset or eval_dataset.Forming the batches to dataset to be trained\n",
        "source :- Hugginface.co**"
      ],
      "metadata": {
        "id": "EHNHOV6qf2y2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P43LaxgSMPtH"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=False, mlm_probability=0.15  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QehKg0pgMPtH"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    \n",
        "    output_dir= \"/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/outputs\",\n",
        "    \n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=8,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    fp16=True,\n",
        "    fp16_opt_level='O1',\n",
        "    warmup_steps=1e2,    \n",
        "    learning_rate=5e-4,\n",
        "    adam_epsilon=1e-8,\n",
        "    weight_decay=0.01,        \n",
        "    save_total_limit=1,\n",
        "    load_best_model_at_end=True,     \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initializing PyTorch Trainer**"
      ],
      "metadata": {
        "id": "YdYBPfDOgQSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n"
      ],
      "metadata": {
        "id": "tio3L6RgtRTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the Tokenizer Object & Starting Training and Saving the model after Finishing the training**"
      ],
      "metadata": {
        "id": "U0-a4ZCvgVa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained('/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/outputs')\n",
        "trainer.train()\n",
        "trainer.save_model() "
      ],
      "metadata": {
        "id": "w8mNi2f_tefA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the Tokenizer**"
      ],
      "metadata": {
        "id": "ygkt0erDgmGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained('/content/drive/MyDrive/Monsoon22_conditional_recipe_gen/outputs')"
      ],
      "metadata": {
        "id": "b2qyn3D2tlzw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}